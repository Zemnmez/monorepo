{
  "tweet": {
    "edit_info": {
      "initial": {
        "editTweetIds": [
          "1045645827203522560"
        ],
        "editableUntil": "2018-09-28T13:06:07.022Z",
        "editsRemaining": "5",
        "isEditEligible": true
      }
    },
    "retweeted": false,
    "source": "<a href=\"http://twitter.com\" rel=\"nofollow\">Twitter Web Client</a>",
    "entities": {
      "hashtags": [],
      "symbols": [],
      "user_mentions": [],
      "urls": []
    },
    "display_text_range": [
      "0",
      "272"
    ],
    "favorite_count": "4",
    "id_str": "1045645827203522560",
    "truncated": false,
    "retweet_count": "1",
    "id": "1045645827203522560",
    "created_at": "Fri Sep 28 12:06:07 +0000 2018",
    "favorited": false,
    "full_text": "now a really interesting AI problem, i think right now is what happens to critical systems that rely on the statistical framework of neural nets? as a by-design sparse and probabilistic model of stuff, there's nearly always an external malicious input that is catastrophic",
    "lang": "en"
  }
}